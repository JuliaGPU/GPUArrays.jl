var documenterSearchIndex = {"docs":
[{"location":"functionality/device/#AbstractDeviceArray","page":"AbstractDeviceArray","title":"AbstractDeviceArray","text":"","category":"section"},{"location":"functionality/device/","page":"AbstractDeviceArray","title":"AbstractDeviceArray","text":"TODO: describe functionality","category":"page"},{"location":"functionality/host/#AbstractGPUArray","page":"AbstractGPUArray","title":"AbstractGPUArray","text":"","category":"section"},{"location":"functionality/host/","page":"AbstractGPUArray","title":"AbstractGPUArray","text":"TODO: describe functionality","category":"page"},{"location":"interface/#Interface","page":"Interface","title":"Interface","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"To extend the above functionality to a new array type, you should use the types and implement the interfaces listed on this page. GPUArrays is designed around having two different array types to represent a GPU array: one that exists only on the host, and one that actually can be instantiated on the device (i.e. in kernels). Device functionality is then handled by KernelAbstractions.jl.","category":"page"},{"location":"interface/#Host-abstractions","page":"Interface","title":"Host abstractions","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"You should provide an array type that builds on the AbstractGPUArray supertype, such as:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"mutable struct CustomArray{T, N} <: AbstractGPUArray{T, N}\n    data::DataRef{Vector{UInt8}}\n    offset::Int\n    dims::Dims{N}\n    ...\nend\n","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"This will allow your defined type (in this case JLArray) to use the GPUArrays interface where available. To be able to actually use the functionality that is defined for AbstractGPUArrays, you need to define the backend, like so:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"import KernelAbstractions: Backend\nstruct CustomBackend <: KernelAbstractions.GPU\nKernelAbstractions.get_backend(a::CA) where CA <: CustomArray = CustomBackend()","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"There are numerous examples of potential interfaces for GPUArrays, such as with JLArrays, CuArrays, and ROCArrays.","category":"page"},{"location":"interface/#Caching-Allocator","page":"Interface","title":"Caching Allocator","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"GPUArrays.@cached\nGPUArrays.@uncached","category":"page"},{"location":"interface/#GPUArrays.@cached","page":"Interface","title":"GPUArrays.@cached","text":"@cached(cache, expr)\n\nEvaluate expr using allocations cache cache.\n\nWhen GPU memory is allocated during the execution of expr, cache will first be checked. If no memory is available in the cache, a new allocation will be requested.\n\nAfter the execution of expr, all allocations made under the scope of @cached will be cached within cache for future use. This is useful to avoid relying on GC to free GPU memory in time.\n\nOnce cache goes out scope, or when the user calls unsafe_free! on it, all cached allocations will be freed.\n\nExample\n\nIn the following example, each iteration of the for-loop requires 8 GiB of GPU memory. Without caching those allocations, significant pressure would be put on the GC, resulting in high memory usage and latency. By using the allocator cache, the memory usage is stable:\n\ncache = GPUArrays.AllocCache()\nfor i in 1:1000\n    GPUArrays.@cached cache begin\n        sin.(CUDA.rand(Float32, 1024^3))\n    end\nend\n\n# optionally: free the memory now, instead of waiting for the GC to collect `cache`\nGPUArrays.unsafe_free!(cache)\n\nSee @uncached.\n\n\n\n\n\n","category":"macro"},{"location":"interface/#GPUArrays.@uncached","page":"Interface","title":"GPUArrays.@uncached","text":"uncached(expr)\n\nEvaluate expression expr without using the allocation. This is useful to call from within @cached to avoid caching some allocations, e.g., because they can be returned out of the @cached scope.\n\n\n\n\n\n","category":"macro"},{"location":"testsuite/#Test-suite","page":"Test suite","title":"Test suite","text":"","category":"section"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"GPUArrays provides an extensive test suite that covers all of the functionality that should be available after implementing the required interfaces. This test suite is part of this package, but for dependency reasons it is not available when importing the package. Instead, you should include the code from your runtests.jl as follows:","category":"page"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"import GPUArrays\ngpuarrays = pathof(GPUArrays)\ngpuarrays_root = dirname(dirname(gpuarrays))\ninclude(joinpath(gpuarrays_root, \"test\", \"testsuite.jl\"))","category":"page"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"With this set-up, you can run the test suite like this:","category":"page"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"TestSuite.test(MyGPUArrayType)","category":"page"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"If you don't want to run the whole suite, you can also run parts of it:","category":"page"},{"location":"testsuite/","page":"Test suite","title":"Test suite","text":"T = JLArray\nGPUArrays.allowscalar(false) # fail tests when slow indexing path into Array type is used.\n\nTestSuite.test_gpuinterface(T) # interface functions like gpu_call, threadidx, etc\nTestSuite.test_base(T) # basic functionality like launching a kernel on the GPU and Base operations\nTestSuite.test_blas(T) # tests the blas interface\nTestSuite.test_broadcasting(T) # tests the broadcasting implementation\nTestSuite.test_construction(T) # tests all kinds of different ways of constructing the array\nTestSuite.test_linalg(T) # linalg function tests\nTestSuite.test_mapreduce(T) # mapreduce sum, etc\nTestSuite.test_indexing(T) # indexing tests\nTestSuite.test_random(T) # randomly constructed arrays\nTestSuite.test_io(T)","category":"page"},{"location":"#GPUArrays.jl","page":"Home","title":"GPUArrays.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"GPUArrays is a package that provides reusable GPU array functionality for Julia's various GPU backends. Think of it as the AbstractArray interface from Base, but for GPU array types. It allows you to write generic julia code for all GPU platforms and implements common algorithms for the GPU. Like Julia Base, this includes BLAS wrapper, FFTs, maps, broadcasts and mapreduces. So when you inherit from GPUArrays and overload the interface correctly, you will get a lot of functionality for free. This will allow to have multiple GPUArray implementation for different purposes, while maximizing the ability to share code.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is not intended for end users! Instead, you should use one of the packages that builds on GPUArrays.jl such as CUDA, AMDGPU, OneAPI, or Metal.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This documentation is meant for users who might wish to implement a version of GPUArrays for another GPU backend and will cover the features you will need to implement, the functionality you gain by doing so, and the test suite that is available to verify your implementation. GPUArrays.jl also provides a reference implementation of these interfaces on the CPU: The JLArray array type uses Julia's parallel programming functionality to simulate GPU execution, and will be used throughout this documentation to illustrate functionality.","category":"page"}]
}
